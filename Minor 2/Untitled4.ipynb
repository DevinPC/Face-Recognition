{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UUmu8Lw4JnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dce7538-6fe8-4f93-e1ac-4d1d5a80c654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.2.1+cu121)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->mediapipe)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->mediapipe)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->mediapipe)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->mediapipe)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->mediapipe)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->mediapipe)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->mediapipe)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->mediapipe)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Zxx2sAaX4Niv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "H8QvKzix4NfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "QLWzksHE4NdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess image using MediaPipe\n",
        "def preprocess_image(image):\n",
        "    mp_face_detection = mp.solutions.face_detection\n",
        "    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)"
      ],
      "metadata": {
        "id": "rgmNrrMQ4NbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load an image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert image to RGB\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "u9TomKgL4NY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize Mediapipe face detection model\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "face_detection = mp_face_detection.FaceDetection()\n",
        "\n",
        "# Load an image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Convert image to RGB\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Detect faces in the image\n",
        "results = face_detection.process(image_rgb)"
      ],
      "metadata": {
        "id": "DvVZse_p4NWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "def detect_faces(image_path):\n",
        "    # Initialize Mediapipe face detection model\n",
        "    mp_face_detection = mp.solutions.face_detection\n",
        "    face_detection = mp_face_detection.FaceDetection()\n",
        "\n",
        "    # Load an image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert image to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    results = face_detection.process(image_rgb)\n",
        "\n",
        "    # Check if any faces are detected\n",
        "    if results.detections:\n",
        "        return True  # Acne detected\n",
        "    else:\n",
        "        return False  # No acne detected\n",
        "\n",
        "# Test the function with an image file\n",
        "print(detect_faces('image.jpg'))"
      ],
      "metadata": {
        "id": "M6ApLW8q4NUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess dataset\n",
        "def train_val_generators(training_dir, validation_dir):\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "    train_generator = train_datagen.flow_from_directory(directory=training_dir,\n",
        "                                                        batch_size=100,\n",
        "                                                        class_mode='categorical',\n",
        "                                                        target_size=(5000, 3500))\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                                  batch_size=100,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  target_size=(512, 520))"
      ],
      "metadata": {
        "id": "U7SZty_V4NR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class DataGenerator(ImageDataGenerator):\n",
        "    pass\n",
        "\n",
        "def create_generators(train_data, valid_data, batch_size):\n",
        "    # Create train generator\n",
        "    train_generator = DataGenerator.flow_from_directory(\n",
        "        train_data,\n",
        "        target_size=(5000, 3500),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical' if num_classes > 2 else 'binary',\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    # Create validation generator\n",
        "    validation_generator = DataGenerator.flow_from_directory(\n",
        "        valid_data,\n",
        "        target_size=(5000, 3500),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical' if num_classes > 2 else 'binary',\n",
        "        rescale=1./255\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "# Test the function with sample data\n",
        "train_data = 'path/to/train/data' # directory path containing train images\n",
        "valid_data = 'path/to/valid/data' # directory path containing validation images\n",
        "batch_size = 100\n",
        "num_classes = 2 # Assuming binary classification, adjust accordingly\n",
        "\n",
        "# The rest of your code remains unchanged\n"
      ],
      "metadata": {
        "id": "VOJi2c4G4NPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KAGGLE_INPUT_PATH = \"/content/drive/MyDrive/Kaggle/Input\"\n",
        "training_dir = os.path.join(KAGGLE_INPUT_PATH, \"Train\")\n",
        "validation_dir = os.path.join(KAGGLE_INPUT_PATH, \"Validation\")"
      ],
      "metadata": {
        "id": "V2hVf7SF4NNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def train_val_generators(training_dir, validation_dir, batch_size):\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        training_dir, target_size=(5000, 3500), batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "    valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    validation_generator = valid_datagen.flow_from_directory(\n",
        "        validation_dir, target_size=(5000, 3500), batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "training_dir = r\"C:\\Users\\ASUS\\Videos\\Minor 2\\archive (5)\\Acne\\Train\"\n",
        "validation_dir = r\"C:\\Users\\ASUS\\Videos\\Minor 2\\archive (5)\\Acne\\Validation\"\n",
        "\n",
        "# Create directories if they do not exist\n",
        "Path(training_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(validation_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Using pathlib to check if the directories exist\n",
        "assert Path(training_dir).exists(), f\"Training directory does not exist: {training_dir}\"\n",
        "assert Path(validation_dir).exists(), f\"Validation directory does not exist: {validation_dir}\"\n",
        "\n",
        "train_generator, validation_generator = train_val_generators(training_dir, validation_dir, batch_size=100)\n"
      ],
      "metadata": {
        "id": "D_f4hGvZ4NLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MobileNet without including the top layer\n",
        "input_shape = (5000, 3500, 3)\n",
        "mobilenet = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "metadata": {
        "id": "ufAmZKMJ4NJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze MobileNet layers\n",
        "for layer in mobilenet.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "99KsXsJD4NGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build your model\n",
        "model = Sequential([\n",
        "    mobilenet,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(3, activation='softmax')   # Assuming binary classification (acne or no acne)\n",
        "])\n"
      ],
      "metadata": {
        "id": "_oxmGhgL4NEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rBW2FyNl4M-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Correct the directory path if necessary\n",
        "train_data_dir = r\"C:\\Users\\ASUS\\Videos\\Minor 2\\archive (5)\\Acne\\Train\"\n",
        "validation_data_dir = r\"C:\\Users\\ASUS\\Videos\\Minor 2\\archive (5)\\Acne\\Train\"\n",
        "\n",
        "# Ensure the directories exist\n",
        "assert os.path.exists(train_data_dir), f\"Training directory does not exist: {train_data_dir}\"\n",
        "assert os.path.exists(validation_data_dir), f\"Validation directory does not exist: {validation_data_dir}\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(5000, 3500),\n",
        "    batch_size=100,\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(5000, 3500),\n",
        "    batch_size=100,\n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "# Your model fitting code here\n",
        "train_generator.reset()\n",
        "validation_generator.reset()\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit()\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        "\n",
        "\n",
        "# Ignore the unrecognized arguments\n",
        "for arg in unknown:\n",
        "    print(f\"Unrecognized argument: {arg}\")\n"
      ],
      "metadata": {
        "id": "Iw-0xGfT4_Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "true_classes = validation_generator.classes\n",
        "predicted_classes = model.predict(validation_generator)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)"
      ],
      "metadata": {
        "id": "bvdf2nG44_MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1_score, support = precision_recall_fscore_support(\n",
        "    true_classes, predicted_classes, average='weighted', labels=np.unique(predicted_classes))"
      ],
      "metadata": {
        "id": "Q0oCqzWR4_Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n"
      ],
      "metadata": {
        "id": "CRSl2MTa4_Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print evaluation metrics\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-Score:', f1_score)\n",
        "print('Accuracy:', accuracy)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "Tf7ONsVD4_FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YdH36h5f4_Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example image for testing\n",
        "example_image_path = \"/content/drive/MyDrive/Kaggle/Input/Train/Acne/acne-scarring-300x300.jpg\"\n",
        "# Provide the path for the example image\n",
        "example_image = cv2.imread(example_image_path)"
      ],
      "metadata": {
        "id": "knCf0YPV5rhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the example image to match the input shape expected by the model\n",
        "example_image_resized = cv2.resize(example_image, (5000, 3500))\n",
        "\n",
        "# Preprocess the example image using MediaPipe\n",
        "has_acne = preprocess_image(example_image_resized)\n",
        "\n",
        "# Predict on the example image\n",
        "example_image_normalized = example_image_resized / 255.0  # Normalize pixel values\n",
        "example_image_normalized = np.expand_dims(example_image_normalized, axis=0)  # Add batch dimension\n",
        "prediction = model.predict(example_image_normalized)"
      ],
      "metadata": {
        "id": "dDBy00AR5reQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the prediction result\n",
        "if has_acne:\n",
        "    print(\"The image has acne.\")\n",
        "else:\n",
        "    print(\"The image does not have acne.\")\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "ILL7UH1G5rWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image\n",
        "plt.imshow(cv2.cvtColor(example_image_resized, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "if has_acne:\n",
        "    plt.title(\"The image has acne. Prediction: {}\".format(prediction))\n",
        "else:\n",
        "    plt.title(\"The image does not have acne. Prediction: {}\".format(prediction))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C9EIeBhW57iH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}